# JDCrawler Backend

JDCrawlerì˜ ë°±ì—”ë“œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. FastAPIë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìœ¼ë©°, ì±„ìš© ì‚¬ì´íŠ¸ í¬ë¡¤ë§, ë°ì´í„° ë¶„ì„ ë° REST APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ”§ Configuration (.env)

`backend/.env` íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ë‹¤ìŒ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

```env
# Database
DATABASE_URL="sqlite:///./data/jobs.db"

# App Settings
HEADLESS=true           # ë¸Œë¼ìš°ì € í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (Falseì¼ ê²½ìš° ë¸Œë¼ìš°ì € ì°½ì´ ë³´ì„)

# AI Settings (Zhipu AI)
ZHIPU_API_KEY="your-api-key"
RATE_LIMIT_DELAY="3.0"  # API ìš”ì²­ ê°„ ë”œë ˆì´ (ì´ˆ)
REQUESTS_PER_MINUTE="10"

# Logging
LOG_LEVEL="INFO"
```

## ğŸ•·ï¸ Crawlers

`jdcrawler/crawlers/` ë””ë ‰í† ë¦¬ì— ê° ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ëŸ¬ê°€ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- **Jobkorea (`jobkorea.py`)**: ì •ì  íŒŒì‹±ê³¼ ë™ì  ë¡œë”©ì„ í˜¼í•©í•˜ì—¬ ì²˜ë¦¬
- **Saramin (`saramin.py`)**: ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ë¶„ì„ì„ í†µí•œ API ì‘ë‹µ í™œìš© ë˜ëŠ” HTML íŒŒì‹±
- **Wanted (`wanted.py`)**: Next.js ê¸°ë°˜ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ì¶° ë°ì´í„° ì¶”ì¶œ

### Adding a New Crawler
1. `jdcrawler/crawlers/base.py`ì˜ `BaseCrawler` í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ìŠµë‹ˆë‹¤.
2. `crawl()` ë° `extract_details()` ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
3. `jdcrawler/services/crawler.py`ì˜ `crawlers` ë”•ì…”ë„ˆë¦¬ì— ë“±ë¡í•©ë‹ˆë‹¤.

## ğŸ“¡ API Endpoints

ì„œë²„ ì‹¤í–‰ í›„ `http://localhost:8000/docs`ì—ì„œ Swagger UIë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Jobs
- `GET /api/jobs`: ì±„ìš© ê³µê³  ëª©ë¡ ì¡°íšŒ (í•„í„°ë§, í˜ì´ì§€ë„¤ì´ì…˜)
- `GET /api/jobs/{job_id}`: ê³µê³  ìƒì„¸ ì¡°íšŒ
- `GET /api/jobs/stats`: ê³µê³  í†µê³„ ë°ì´í„° ì¡°íšŒ

### Keywords
- `GET /api/keywords`: ë“±ë¡ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ ëª©ë¡
- `POST /api/keywords`: ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€
- `PATCH /api/keywords/{keyword_id}`: í‚¤ì›Œë“œ í™œì„±/ë¹„í™œì„± í† ê¸€

### Crawl
- `POST /api/crawl/trigger`: ì¦‰ì‹œ í¬ë¡¤ë§ íŠ¸ë¦¬ê±°
- `GET /api/crawl/status`: í˜„ì¬ í¬ë¡¤ë§ ìƒíƒœ í™•ì¸

## ğŸ§ª Testing

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • íŒŒì¼ í…ŒìŠ¤íŠ¸
pytest tests/test_saramin.py

# Lint & Format
ruff check .
ruff format .
```